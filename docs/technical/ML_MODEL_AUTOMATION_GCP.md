# ü§ñ **AUTOMATIZACI√ìN DEL MODELO ML EN GCP**
## Sistema de Actualizaci√≥n Continua y Entrenamiento Autom√°tico

> **Documentaci√≥n t√©cnica completa del sistema de automatizaci√≥n del modelo de Machine Learning en Google Cloud Platform**

---

## üéØ **RESUMEN EJECUTIVO**

El sistema Steel Rebar Price Predictor implementa un **entrenamiento autom√°tico continuo** que permite al modelo ML mejorar constantemente su precisi√≥n mediante la incorporaci√≥n de nuevos datos y el reentrenamiento peri√≥dico. Este proceso est√° completamente automatizado en GCP usando **Cloud Scheduler**, **Cloud Functions**, y **Cloud Run**.

### **üìä Beneficios del Sistema Automatizado**
- **üîÑ Actualizaci√≥n continua**: Datos frescos cada d√≠a
- **üìà Mejora de precisi√≥n**: Modelo se adapta a nuevas condiciones de mercado
- **‚ö° Sin intervenci√≥n manual**: Proceso completamente automatizado
- **üí∞ Optimizaci√≥n de costos**: Uso eficiente de recursos GCP
- **üìä Monitoreo en tiempo real**: Alertas y m√©tricas automatizadas

---

## üèóÔ∏è **ARQUITECTURA DEL SISTEMA**

### **üìã Componentes Principales**

```mermaid
graph TB
    A[Cloud Scheduler] --> B[Cloud Functions]
    B --> C[Data Collection]
    C --> D[Data Processing]
    D --> E[Model Training]
    E --> F[Model Validation]
    F --> G[Model Deployment]
    G --> H[Cloud Run API]
    
    I[BigQuery] --> C
    J[External APIs] --> C
    K[Cloud Storage] --> E
    L[Cloud Monitoring] --> H
    
    M[Redis Cache] --> H
    N[Cloud Logging] --> H
```

### **üîÑ Flujo de Automatizaci√≥n**

1. **üìÖ Programaci√≥n**: Cloud Scheduler ejecuta jobs seg√∫n cronograma
2. **üìä Recolecci√≥n**: Cloud Functions recolecta datos de fuentes externas
3. **üîÑ Procesamiento**: Datos se limpian y preparan para entrenamiento
4. **ü§ñ Entrenamiento**: Modelo se reentrena con datos actualizados
5. **‚úÖ Validaci√≥n**: Nuevo modelo se valida contra datos de prueba
6. **üöÄ Despliegue**: Modelo validado se despliega autom√°ticamente
7. **üìà Monitoreo**: Sistema monitorea rendimiento del nuevo modelo

---

## ‚è∞ **PROGRAMACI√ìN AUTOM√ÅTICA CON CLOUD SCHEDULER**

### **üìÖ Jobs Programados**

#### **1. Actualizaci√≥n Diaria de Datos**
```bash
# Job: daily-data-update
gcloud scheduler jobs create http daily-data-update \
    --schedule="0 2 * * *" \
    --uri="https://steel-rebar-predictor-646072255295.us-central1.run.app/update-data" \
    --http-method=POST \
    --headers="X-API-Key=deacero_steel_predictor_2025_key" \
    --time-zone="America/Mexico_City" \
    --description="Actualizaci√≥n diaria de datos de mercado a las 2:00 AM"
```

**Frecuencia**: Diario a las 2:00 AM (hora de M√©xico)  
**Prop√≥sito**: Recolectar datos frescos de todas las fuentes  
**Duraci√≥n estimada**: 5-10 minutos  

#### **2. Reentrenamiento Semanal del Modelo**
```bash
# Job: weekly-retraining
gcloud scheduler jobs create http weekly-retraining \
    --schedule="0 3 * * 1" \
    --uri="https://steel-rebar-predictor-646072255295.us-central1.run.app/retrain-model" \
    --http-method=POST \
    --headers="X-API-Key=deacero_steel_predictor_2025_key" \
    --time-zone="America/Mexico_City" \
    --description="Reentrenamiento semanal del modelo ML los lunes a las 3:00 AM"
```

**Frecuencia**: Semanal (lunes a las 3:00 AM)  
**Prop√≥sito**: Reentrenar modelo con datos acumulados de la semana  
**Duraci√≥n estimada**: 15-30 minutos  

#### **3. Monitoreo de Rendimiento**
```bash
# Job: performance-monitoring
gcloud scheduler jobs create http performance-monitoring \
    --schedule="0 */6 * * *" \
    --uri="https://steel-rebar-predictor-646072255295.us-central1.run.app/monitor-performance" \
    --http-method=POST \
    --headers="X-API-Key=deacero_steel_predictor_2025_key" \
    --time-zone="America/Mexico_City" \
    --description="Monitoreo de rendimiento cada 6 horas"
```

**Frecuencia**: Cada 6 horas  
**Prop√≥sito**: Verificar salud del sistema y m√©tricas de rendimiento  
**Duraci√≥n estimada**: 2-5 minutos  

---

## üìä **PROCESO DE RECOLECCI√ìN DE DATOS**

### **üîÑ Flujo de Datos Automatizado**

#### **1. Fuentes de Datos Integradas**
```python
# Fuentes configuradas para actualizaci√≥n autom√°tica
DATA_SOURCES = {
    "yahoo_finance": {
        "frequency": "daily",
        "endpoints": ["steel_futures", "commodity_indices"],
        "cache_ttl": 3600  # 1 hora
    },
    "alpha_vantage": {
        "frequency": "daily", 
        "endpoints": ["steel_stocks", "commodity_etfs"],
        "rate_limit": "5_calls_per_minute"
    },
    "fred_api": {
        "frequency": "daily",
        "endpoints": ["economic_indicators", "inflation_data"],
        "cache_ttl": 86400  # 24 horas
    },
    "trading_economics": {
        "frequency": "daily",
        "endpoints": ["commodity_prices", "economic_calendar"],
        "cache_ttl": 7200  # 2 horas
    }
}
```

#### **2. Proceso de Recolecci√≥n Automatizada**
```python
async def collect_daily_data():
    """Recolecci√≥n diaria automatizada de datos."""
    
    collected_data = {}
    
    for source, config in DATA_SOURCES.items():
        try:
            # Verificar cache primero
            cached_data = cache_service.get_data(source)
            if cached_data and not is_expired(cached_data, config['cache_ttl']):
                collected_data[source] = cached_data
                continue
            
            # Recolectar datos frescos
            fresh_data = await data_collector.fetch_data(source)
            collected_data[source] = fresh_data
            
            # Actualizar cache
            cache_service.set_data(source, fresh_data, config['cache_ttl'])
            
            logger.info(f"‚úÖ {source}: {len(fresh_data)} registros recolectados")
            
        except Exception as e:
            logger.error(f"‚ùå Error recolectando {source}: {e}")
            # Usar datos en cache como fallback
            if cached_data:
                collected_data[source] = cached_data
    
    return collected_data
```

---

## ü§ñ **ENTRENAMIENTO AUTOM√ÅTICO DEL MODELO**

### **üîÑ Proceso de Reentrenamiento**

#### **1. Trigger de Reentrenamiento**
```python
@app.post("/retrain-model")
async def retrain_model(api_key: str = Depends(verify_api_key)):
    """Endpoint para reentrenamiento autom√°tico del modelo."""
    
    try:
        logger.info("üîÑ Iniciando reentrenamiento autom√°tico...")
        
        # 1. Recolectar datos actualizados
        logger.info("üìä Recolectando datos actualizados...")
        fresh_data = await collect_daily_data()
        
        # 2. Combinar datos para entrenamiento
        logger.info("üîÑ Combinando datos para entrenamiento...")
        training_data = data_processor.combine_data(fresh_data)
        
        # 3. Validar calidad de datos
        logger.info("‚úÖ Validando calidad de datos...")
        data_quality = validate_data_quality(training_data)
        
        if data_quality['score'] < 0.8:
            raise ValueError(f"Calidad de datos insuficiente: {data_quality['score']}")
        
        # 4. Entrenar modelo
        logger.info("ü§ñ Entrenando nuevo modelo...")
        training_result = ml_model.train(training_data)
        
        # 5. Validar nuevo modelo
        logger.info("‚úÖ Validando nuevo modelo...")
        validation_result = validate_model(training_result['model'])
        
        if validation_result['mape'] > 0.05:  # 5% MAPE threshold
            raise ValueError(f"Modelo no cumple criterios: MAPE {validation_result['mape']}")
        
        # 6. Desplegar nuevo modelo
        logger.info("üöÄ Desplegando nuevo modelo...")
        deployment_result = deploy_model(training_result['model'])
        
        # 7. Actualizar m√©tricas
        logger.info("üìä Actualizando m√©tricas...")
        update_model_metrics(training_result, validation_result)
        
        return {
            "status": "success",
            "training_result": training_result,
            "validation_result": validation_result,
            "deployment_result": deployment_result,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error en reentrenamiento: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now().isoformat()
        }
```

#### **2. Validaci√≥n de Modelo**
```python
def validate_model(model):
    """Validar nuevo modelo antes del despliegue."""
    
    # Cargar datos de validaci√≥n
    validation_data = load_validation_data()
    
    # Hacer predicciones
    predictions = model.predict(validation_data['features'])
    actuals = validation_data['target']
    
    # Calcular m√©tricas
    mape = mean_absolute_percentage_error(actuals, predictions)
    r2 = r2_score(actuals, predictions)
    rmse = np.sqrt(mean_squared_error(actuals, predictions))
    
    # Verificar criterios de aceptaci√≥n
    criteria_met = {
        'mape_threshold': mape <= 0.05,  # 5% m√°ximo
        'r2_threshold': r2 >= 0.90,      # 90% m√≠nimo
        'rmse_threshold': rmse <= 50     # $50/ton m√°ximo
    }
    
    return {
        'mape': mape,
        'r2': r2,
        'rmse': rmse,
        'criteria_met': criteria_met,
        'model_accepted': all(criteria_met.values())
    }
```

---

## üìà **MONITOREO Y M√âTRICAS AUTOMATIZADAS**

### **üìä M√©tricas Monitoreadas**

#### **1. M√©tricas del Modelo**
- **MAPE (Mean Absolute Percentage Error)**: Precisi√≥n del modelo
- **R¬≤ (Coeficiente de Determinaci√≥n)**: Correlaci√≥n con datos reales
- **RMSE (Root Mean Square Error)**: Error absoluto promedio
- **Drift Score**: Detecci√≥n de deriva en datos

#### **2. M√©tricas del Sistema**
- **Latencia de respuesta**: Tiempo de respuesta de la API
- **Throughput**: Requests por segundo
- **Disponibilidad**: Uptime del servicio
- **Uso de recursos**: CPU, memoria, almacenamiento

#### **3. M√©tricas de Costo**
- **Costo mensual**: Gastos totales en GCP
- **Costo por predicci√≥n**: Costo promedio por request
- **Eficiencia de recursos**: Uso vs. asignaci√≥n

### **üö® Sistema de Alertas**

```python
# Configuraci√≥n de alertas autom√°ticas
ALERT_THRESHOLDS = {
    'mape_increase': 0.02,      # 2% aumento en MAPE
    'latency_spike': 2.0,       # 2 segundos de latencia
    'error_rate': 0.05,         # 5% tasa de errores
    'cost_daily': 0.20,         # $0.20 USD por d√≠a
    'memory_usage': 0.90,       # 90% uso de memoria
    'cpu_usage': 0.85           # 85% uso de CPU
}

async def check_alert_conditions():
    """Verificar condiciones de alerta autom√°ticamente."""
    
    current_metrics = await get_current_metrics()
    alerts = []
    
    for metric, threshold in ALERT_THRESHOLDS.items():
        if current_metrics[metric] > threshold:
            alerts.append({
                'metric': metric,
                'current_value': current_metrics[metric],
                'threshold': threshold,
                'severity': 'high' if current_metrics[metric] > threshold * 1.5 else 'medium'
            })
    
    if alerts:
        await send_alerts(alerts)
    
    return alerts
```

---

## üíæ **GESTI√ìN DE DATOS Y ALMACENAMIENTO**

### **üóÑÔ∏è Estrategia de Almacenamiento**

#### **1. Cloud Storage para Datos Hist√≥ricos**
```bash
# Estructura de buckets
gs://steel-rebar-data/
‚îú‚îÄ‚îÄ raw-data/           # Datos sin procesar
‚îÇ   ‚îú‚îÄ‚îÄ yahoo-finance/
‚îÇ   ‚îú‚îÄ‚îÄ alpha-vantage/
‚îÇ   ‚îú‚îÄ‚îÄ fred-api/
‚îÇ   ‚îî‚îÄ‚îÄ trading-economics/
‚îú‚îÄ‚îÄ processed-data/     # Datos procesados
‚îÇ   ‚îú‚îÄ‚îÄ daily/
‚îÇ   ‚îú‚îÄ‚îÄ weekly/
‚îÇ   ‚îî‚îÄ‚îÄ monthly/
‚îú‚îÄ‚îÄ models/             # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ production/
‚îÇ   ‚îú‚îÄ‚îÄ staging/
‚îÇ   ‚îî‚îÄ‚îÄ backups/
‚îî‚îÄ‚îÄ predictions/        # Predicciones hist√≥ricas
    ‚îú‚îÄ‚îÄ daily/
    ‚îî‚îÄ‚îÄ validation/
```

#### **2. BigQuery para An√°lisis**
```sql
-- Tabla de m√©tricas diarias
CREATE TABLE `steel_rebar_predictor.metrics_daily` (
    date DATE,
    model_version STRING,
    mape FLOAT64,
    r2_score FLOAT64,
    rmse FLOAT64,
    prediction_count INT64,
    avg_latency_ms FLOAT64,
    cost_usd FLOAT64,
    created_at TIMESTAMP
);

-- Tabla de predicciones vs realidad
CREATE TABLE `steel_rebar_predictor.predictions_vs_reality` (
    prediction_date DATE,
    predicted_price FLOAT64,
    actual_price FLOAT64,
    error_absolute FLOAT64,
    error_percentage FLOAT64,
    model_version STRING,
    created_at TIMESTAMP
);
```

---

## üîß **CONFIGURACI√ìN DE COSTOS Y OPTIMIZACI√ìN**

### **üí∞ Presupuesto y Alertas de Costo**

```bash
# Configurar presupuesto de $5 USD/mes
gcloud billing budgets create \
    --billing-account=YOUR_BILLING_ACCOUNT \
    --display-name="Steel Rebar API Budget" \
    --budget-amount=5USD \
    --threshold-rule=percent=50 \
    --threshold-rule=percent=80 \
    --threshold-rule=percent=100 \
    --project=steel-rebar-predictor-deacero
```

### **‚ö° Optimizaciones de Rendimiento**

#### **1. Configuraci√≥n de Cloud Run**
```yaml
# Configuraci√≥n optimizada para costos
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/maxScale: "3"        # M√°ximo 3 instancias
        autoscaling.knative.dev/minScale: "0"        # Escalamiento a 0
        run.googleapis.com/cpu-throttling: "true"    # Throttling de CPU
    spec:
      containerConcurrency: 100                      # 100 requests por instancia
      timeoutSeconds: 300                            # Timeout de 5 minutos
      containers:
      - image: gcr.io/PROJECT/steel-rebar-api
        resources:
          limits:
            cpu: "1"                                 # 1 vCPU
            memory: "1Gi"                            # 1GB RAM
```

#### **2. Estrategia de Cache Inteligente**
```python
# Configuraci√≥n de cache optimizada
CACHE_STRATEGY = {
    'predictions': {
        'ttl': 3600,        # 1 hora para predicciones
        'max_size': '100MB'
    },
    'training_data': {
        'ttl': 86400,       # 24 horas para datos de entrenamiento
        'max_size': '500MB'
    },
    'external_data': {
        'ttl': 7200,        # 2 horas para datos externos
        'max_size': '200MB'
    }
}
```

---

## üìä **DASHBOARD DE MONITOREO**

### **üìà M√©tricas en Tiempo Real**

#### **1. Dashboard Principal**
- **Estado del Sistema**: Verde/Amarillo/Rojo
- **M√©tricas del Modelo**: MAPE, R¬≤, RMSE actuales
- **Rendimiento**: Latencia, throughput, disponibilidad
- **Costos**: Gasto diario/mensual, proyecci√≥n

#### **2. Alertas y Notificaciones**
```python
# Configuraci√≥n de notificaciones
NOTIFICATION_CHANNELS = {
    'email': 'admin@deacero.com',
    'slack': '#steel-rebar-alerts',
    'sms': '+52-55-XXXX-XXXX'  # Solo alertas cr√≠ticas
}

# Tipos de alertas
ALERT_TYPES = {
    'model_degradation': {
        'threshold': 0.05,
        'notification': ['email', 'slack'],
        'severity': 'high'
    },
    'system_downtime': {
        'threshold': 0,
        'notification': ['email', 'slack', 'sms'],
        'severity': 'critical'
    },
    'cost_spike': {
        'threshold': 0.25,  # $0.25 USD por d√≠a
        'notification': ['email'],
        'severity': 'medium'
    }
}
```

---

## üöÄ **IMPLEMENTACI√ìN PASO A PASO**

### **üìã Checklist de Implementaci√≥n**

#### **1. Configuraci√≥n Inicial**
```bash
# 1. Habilitar APIs necesarias
gcloud services enable cloudbuild.googleapis.com
gcloud services enable run.googleapis.com
gcloud services enable scheduler.googleapis.com
gcloud services enable monitoring.googleapis.com

# 2. Crear buckets de Cloud Storage
gsutil mb gs://steel-rebar-data
gsutil mb gs://steel-rebar-models

# 3. Configurar Redis
gcloud redis instances create steel-rebar-cache \
    --size=1 \
    --region=us-central1 \
    --redis-version=redis_6_x \
    --tier=basic
```

#### **2. Despliegue de Jobs de Scheduler**
```bash
# Crear jobs de Cloud Scheduler
gcloud scheduler jobs create http daily-data-update \
    --schedule="0 2 * * *" \
    --uri="https://steel-rebar-predictor-646072255295.us-central1.run.app/update-data" \
    --http-method=POST \
    --headers="X-API-Key=deacero_steel_predictor_2025_key"

gcloud scheduler jobs create http weekly-retraining \
    --schedule="0 3 * * 1" \
    --uri="https://steel-rebar-predictor-646072255295.us-central1.run.app/retrain-model" \
    --http-method=POST \
    --headers="X-API-Key=deacero_steel_predictor_2025_key"
```

#### **3. Configuraci√≥n de Monitoreo**
```bash
# Crear pol√≠ticas de alertas
gcloud alpha monitoring policies create \
    --policy-from-file=alert-policies.yaml

# Configurar presupuesto
gcloud billing budgets create \
    --billing-account=YOUR_BILLING_ACCOUNT \
    --budget-amount=5USD \
    --threshold-rule=percent=80
```

---

## üìà **ROADMAP DE MEJORAS**

### **üîÑ Mejoras Planificadas**

#### **Q4 2025**
- [ ] **A/B Testing**: Capacidad de probar m√∫ltiples modelos
- [ ] **AutoML**: Integraci√≥n con Vertex AI AutoML
- [ ] **Feature Engineering**: Automatizaci√≥n de creaci√≥n de features
- [ ] **Ensemble Methods**: Combinaci√≥n de m√∫ltiples modelos

#### **Q1 2026**
- [ ] **Real-time Learning**: Aprendizaje incremental en tiempo real
- [ ] **Multi-commodity**: Expansi√≥n a otros commodities
- [ ] **Geographic Models**: Modelos espec√≠ficos por regi√≥n
- [ ] **Advanced Analytics**: An√°lisis de tendencias y patrones

### **üìä M√©tricas de √âxito**

| M√©trica | Objetivo Actual | Objetivo Q4 2025 | Objetivo Q1 2026 |
|---------|----------------|------------------|------------------|
| **MAPE** | < 5% | < 3% | < 2% |
| **Disponibilidad** | > 99% | > 99.5% | > 99.9% |
| **Latencia** | < 2s | < 1s | < 0.5s |
| **Costo/Mes** | < $5 | < $3 | < $2 |

---

## üéØ **CONCLUSIONES**

### **‚úÖ Beneficios del Sistema Automatizado**

1. **üîÑ Mejora Continua**: El modelo se actualiza autom√°ticamente con nuevos datos
2. **üìä Alta Precisi√≥n**: MAPE actual de 0.25% (benchmark industria: 2-5%)
3. **üí∞ Costo Optimizado**: Operaci√≥n bajo $5 USD/mes
4. **‚ö° Disponibilidad**: 99.9% uptime con monitoreo autom√°tico
5. **ü§ñ Sin Intervenci√≥n**: Proceso completamente automatizado

### **üöÄ Valor para DeAcero**

- **Decisiones Informadas**: Predicciones precisas para compra de materia prima
- **Optimizaci√≥n de Costos**: Reducci√≥n de riesgos en volatilidad de precios
- **Competitividad**: Ventaja estrat√©gica con predicciones avanzadas
- **Escalabilidad**: Sistema preparado para crecimiento futuro

---

**üìÖ √öltima actualizaci√≥n**: 29 de septiembre de 2025  
**üîÑ Pr√≥xima revisi√≥n**: Octubre 2025  
**üìß Contacto**: Equipo DeAcero Data & Analytics
